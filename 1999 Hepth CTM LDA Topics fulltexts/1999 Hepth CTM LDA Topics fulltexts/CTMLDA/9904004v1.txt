the light-cone gauge without prescriptions

instituto de fsica teorica, universidade estadual paulista, r.pamplona, 145 sao paulo - sp cep 01405-900 brazil

a. t. suzuki and a. g. m. schmidt

(june 17, 2011)

feynman integrals in the physical light-cone gauge are harder to solve than their covariant
counterparts. the diculty is associated with the presence of unphysical singularities due to the
inherent residual gauge freedom in the intermediate boson propagators constrained within this gauge
choice. in order to circumvent these non-physical singularities, the headlong approach has always
been to call for mathematical devices  prescriptions  some successful ones and others not so
much so. a more elegant approach is to consider the propagator from its physical point of view,
that is, an object obeying basic principles such as causality. once this fact is realized and carefully
taken into account, the crutch of prescriptions can be avoided altogether. an alternative third
approach, which for practical computations could dispense with prescriptions as well as prescinding
the necessity of careful stepwise watching out of causality would be of great advantage. and this
third option is realizable within the context of negative dimensions, or as it has been coined, negative
dimensional integration method, ndim for short.

key-words: light-cone gauge, prescriptionless, negative dimensional integration

02.90+p, 11.15.bt

light-cone gauge in quantum eld theory is a fascinating subject. it is a simple gauge choice in the sense that
the emerging propagator for the boson eld has a deceivingly simple structure, when compared to other non-covariant
gauge choices. yet, as it has soon been realized, it hid subtle complications when one actually wanted to work with
it.

to make things more concrete, let us analyse it in the framework of vector gauge elds, e.g. the pure yang-mills

elds, where, after taking the limit of vanishing gauge parameter, the propagator reads:

dab

(k) =

i ab

k2 + i (cid:20)g 

nk + n k

kn

(cid:21)

(1)

where n is the arbritary and constant null four-vector which denes the gauge, naa(x) = 0; n2 = 0. this generates
d-dimensional feynman integrals of the following generic form:

ilc = z

ddki

a(kj , pl)

f (kj n, pl n)
h(kj n, pl n)

,

(2)

where pl labels all the external momenta, and n
 is a null four-vector, dual to n. a conspicuous feature that we need
to note rst of all, is that the dual vector n
, when it appears at all, it does so always and only in the numerators
of the integrands. and herein comes the rst seemingly misterious facet of light-cone gauge. how come that from
a propagator expression like (1), which contains no n factors, can arise integrals of the form (2), with prominently
seen n factors? again, this is most easily seen in the framework of denite external vectors n and n. an alternative
way of writing the generic form of a light-cone integral is

i 1n
lc

= z

ddki

a(kj , pl)

g(kj
j , pl
l )
h(kj n, pl n)

,

(3)

9
9
9
1

 
r
p
a
1

 

 
 

1
v
4
0
0
4
0
9
9
/
h
t
-
p
e
h
:
v
i
x
r
a

j

j , pl

l ) denes a tensorial structure in the integral. for a vector, we have k = (k+, k, kt),
where the numerator g(k
where k+ = (k0 + kd1) and k = (k0  kd1) with  being a normalization factor. if we choose denite n and
 = (1, 0,    , 1), this allows us to write k+  k n and k  k n. we
n such that n = (1, 0,    , 1), and n
have therefore traced back the origin for the numerator factors containing n. by the way, these terms have nothing
whatsoever to do with some kind of prescription input as it is in (8) below. there, the n factors are added into the
structure by hand via the ad hoc prescription.

e-mail:suzuki@ift.unesp.br
e-mail:schmidt@ift.unesp.br

1

now, the troublesome factors in the denominator, represented by h(kj n, pl n), for one-loop, two-point functions

are typically products of the form

1

h(kj n, pl n)



1

(k  n) (k  p)  n

.

(4)

in the standard approach, these are dealt with rst by partial fractioning them, a trick sometimes called decom-

position formula (see, for example, [1,2])

1

(kn) (p  k)n



1

pn (cid:20) 1

kn

+

1

(p  k)n(cid:21) ,

pn 6= 0

(5)

it is easy to see that such kind of trick becomes very clumsy to deal with when one has higher powers of denominator

factors. for example, consider,

1

(kn)2 (p  k)n



1

(pn)2 (cid:20) pn

(kn)2 +

1

kn

+

1

(p  k)n(cid:21) ,

pn 6= 0

(6)

and so on and so forth. yet, the standard approach based upon prescriptions, cannot handle denominator products
like these without rst decomposing them. although no one has said it explicitly before, decomposition formulas like
(5) and (6) are in fact part of the prescription. be it as it is, after the decomposition is made, then and only then, one
seeks to handle the isolated denominators calling for prescriptions that would turn them manageable mathematically.

early eorts in this direction draw heavily from the use of the cauchy principal value (cpv or pv for short),

p v (cid:18) 1

q n(cid:19) 

1
2

0(cid:18)

lim

1

q n + i

+

1

q n  i(cid:19) .

(7)

unfortunately, this prescription, although preserves the general structure of the light-cone integral (2), and is math-
ematically consistent, does not provide physically acceptable results in the light-cone gauge [3,4].

later on, independently mandelstam [5] and leibbrandt [6] proposed new prescriptions to treat the gauge-dependent

poles,

1
q n



=

1

q n + i sgn(q n)

q n

(q n) (q n) + i

.

(8)

where the former is the modied mandelstam prescription and the latter is the leibbrandts one. it can be proven
that, in fact, they are completely equivalent to each other, so that sometimes people refer to this as the mandelstam-
leibbrandt (ml) prescription. a conspicuous feature of these prescriptions is that they introduce the factor (q  n)
in the denominator of integrals, thus modifying the original structure. this, however, does not seem to aect the end
result, as far as physically meaningful results are concerned.

applying the ml prescription for example, in the one-loop two-point function integrals, double poles still appear
but they cancel against each other and one is left with physical poles only. in other words, those singularities that are
merely gauge artifacts cancel out when one uses this approach. experts [4] argue, therefore, that adopting the ml
prescription makes the light-cone gauge acceptable, at least perturbatively. along this line, some two-loop calculations
have been performed explicitly and can be found in the pertinent literature [7]

pimentel et al. realized that when the physical principle of causality is correctly taken into account  either by
careful, stepwise watching out for it to be preserved along the whole computation, or by implementing it directly onto
the propagator, via causal considerations the same picture arises, namely, unphysical, gauge-dependent poles cancel
out leaving solely physical ones [8,9]. actually, the procedure corresponds exactly to taking out the zero-frequency
mode from the fourier series expansion for the eld operators, ensuring that only positive energy quanta propagate
to future and vice versa. mathematically this can be acomplished via

1

(q n)j = p v (cid:18) 1

(q n)j(cid:19)  i

(1)j1
(j  1)!

(j1)(q n) sgn(q0),

(9)

where p v stands for cauchy principal value. the second term of this expression is crucial.
it is the term that
guarantees that the troublesome zero-frequency mode of the eld quanta is subtracted out from the energy spectrum.

2

it is exactly tantamount to avoiding the pathological mixing of quanta of opposite energy signs propagating to future,
thus violating causality.

by the very nature in which these prescriptions are introduced, they are completely powerless to deal with products
of light-cone poles without ere using the partial fractioning trick. moreover, in addition to the need to use the
decomposition formula, the necessity to resort to prescriptions or even clever maneuvers in order to extract out
the culprit factor from the original integral is an awkward trail to walk along to reach our objective. because a
prescription is solely a prescription, a mere device to by-pass a problem, prescriptions are usually inconvenient and
undesirable. yet, as awkward and burdensome as it might be, there was no other way we could do things properly in
dealing with perturbative light-cone gauge computations.

not so now, with the advent of ndim [10]. ndim is a technique wherein the principle of analytic continuation
plays a key role. with it we solve a feynman-like polynomial fermionic integral, i.e., a loop integral in negative d-
dimensional space with propagators raised to positive powers in the numerator. solutions arise as linear combinations
of solutions for simple systems of linear equations and these are then analytically continued to allow for negative values
of exponents (i.e. propagators now become raised to negative powers, becoming denominator terms in the integrands)
and positive dimension [11]. this procedure, of course, when applied to the light-cone case has to consider the general
structure (2) above which is characteristic of this gauge. that is, terms like f (kj n, pl n)  (q n)a[(q  p)n]b
which can appear in the numerator, evidently must remain there; therefore, no exponents of such terms are to be
analytically continued to allow for negative values [12]. schematically,

z ddki a(kj , pl) f (kj n, pl n) h(kj n, pl n) ac z

ddki

a(kj , pl)

f (kj n, pl n)
h(kj n, pl n)

(10)

where the left-hand side shows the negative dimensional integral to be performed and the right-hand side displays
the generic form (2) for the light-cone integrals. note that the factor f (kj  n, pl  n) remains in the numerator
of the integrands in both sides. the left-hand side of (10), which is evaluated via ndim methodology, is dened
from projecting out powers of gaussian type d-dimensional momentum integrals of propagators [10]. it is worth
mentioning here that the usual schwinger exponentiation of propagators for the factor [h(kj n, pl n)]1 in positive
dimensional calculation does not work for light-cone integrals [9].

this ndim technique is therefore the most powerful and beautiful machinery ever to come to front until now to
handle the light-cone feynman integrals. all the desirable features are embedded in it and we can list them as follows:
i) no decomposition formula like (5) is needed to separate gauge dependent poles before the integral is evaluated;
ii) it preserves the general structure of the light-cone integral, namely, no alien factors containing n are introduced
in the denominators; iii) no prescription is needed to handle (q  n) = 0 type singularities to solve the integral; iv)
there are no parametric integrals to perform; v) there is no need to split the dimensionality of space-time to work
out integrations over component sub-spaces like in [2]; vi) results are obtained for arbitrary negative exponents of
propagators and gauge-dependent poles, so that special cases are contained in them; vii) results are always within
the context of dimensional regularization, i.e., preserving gauge symmetry.

the power of ndim is therefore readily apparent. if one remembers how integrals over grassmann variables are
introduced, he can recall that the underlying property employed to dene them is translation invariance. it is an
outstanding thing that this sole property in the fermionic integration is able to guarantee a prescriptionless light-cone
and more important than that, a causality preserving method of direct computation of feynman integrals.

a.g.m.s. gratefully acknowledges fapesp (fundacao de amparo `a pesquisa do estado de sao paulo, brasil) for

nancial support.

acknowledgments

[1] g.leibbrandt, rev.mod.phys. 59 (1987) 1067. g.leibbrandt, non-covariant gauges: quantization of yang-mills and

chern-simons theory in axial type gauges, world scientic (1994).

[2] g.leibbrandt, s.nyeo, j.math.phys. 27 (1986) 627.
[3] a.bassetto, g.nardelli, r.soldati, yang-mills theories in algebraic non-covarinat gauges, world scientic (1991)
[4] a.bassetto, in lecture notes in physics, 61, p.gaigg, w.kummer, m.schweda (eds.), springer-verlag (1989).

3

[5] s.mandelstam, nucl.phys.b 213 (1983) 149.
[6] g.leibbrandt, phys.rev.d 29 (1984) 1699.
[7] d.m.capper, d.r.t.jones, and a.t.suzuki, z.phys.c 29 (1985) 585. g.leibbrandt, and s-l.nyeo, j.math.phys. 27
(1986) 627. g.heinrich, and z.kunszt, nucl.phys. b 519 (1998) 405. a.basseto, g.heinrich, z.kunszt, and w.vogelsang,
phys.rev. d 58 (1998) 094020.

[8] b.m.pimentel, a.t.suzuki, phys.rev. d42 (1990) 2115. c.g.bollini, j.j.giambiagi, a.gonzalez dominguez, j.math.phys.

6 (1965) 165. b.m.pimentel, a.t.suzuki, mod.phys.lett. a6 (1991) 2649.

[9] a.t.suzuki, mod.phys.lett. a8 (1993) 2365.

[10] i.g.halliday, r.m.ricotta, phys.lett. b193 (1987) 241.
[11] a.t.suzuki, a.g.m.schmidt, eur.phys.j.c5 (1998) 175. a.t.suzuki, a.g.m.schmidt, j.phys.a31 (1998) 8023.
a.t.suzuki, a.g.m.schmidt, jhep 09 (1997) 002. jhep is an electronic journal, see for instance its web mirrors:
http://jhep.sissa.it. a.t.suzuki, a.g.m.schmidt, phys.rev.d58 (1998) 047701.

[12] a.t.suzuki, a.g.m.schmidt, nucl.phys. b537 (1999) 549.

4

